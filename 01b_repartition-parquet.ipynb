{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Repartition the parquet data\n",
    "\n",
    "The data downloaded from the database is supposed to be downloaded in equal sized chunks, but this doesn't always work out as expected. This notebook does a repartition aiming for around 300MB per parquet file. \n",
    "\n",
    "NB: Afterwards, manually replace the old parquet folder with the reparitioned folder. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask_geopandas as dgp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dgp.read_parquet(\"data/parquet/\")\n",
    "df = df.repartition(npartitions=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dgp.to_parquet(df, \"./data/parquet_repartitioned/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
